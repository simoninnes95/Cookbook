df.na.drop(subset=["col_X"])

df.filter(df.col_X.isNotNull())

# cast types
from pyspark.sql.types import IntegerType

df = df.withColumn("pipe_width", F.col("pipe_width").cast(IntegerType()))

# count distinct

df.select(F.countDistinct("colName")).show()

# max or min

df.select(F.min("DateTime")).show()

# filter based on list

not in list
df.filter(~F.col("SiteID").isin(list))